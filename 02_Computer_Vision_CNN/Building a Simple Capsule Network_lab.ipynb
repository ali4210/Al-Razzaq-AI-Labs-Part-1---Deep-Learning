{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-12-17T04:24:03.650595Z",
     "start_time": "2025-12-17T04:23:59.943041Z"
    }
   },
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, datasets, utils\n",
    "import numpy as np"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-17T04:24:22.067269Z",
     "start_time": "2025-12-17T04:24:22.063333Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class CapsuleLayer(layers.Layer):\n",
    "    def __init__(self, num_capsules, dim_capsules, routings=3, **kwargs):\n",
    "        super(CapsuleLayer, self).__init__(**kwargs)\n",
    "        self.num_capsules = num_capsules\n",
    "        self.dim_capsules = dim_capsules\n",
    "        self.routings = routings\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        # Dimensions: (num_capsules, input-num-capsules, dim_capsules, input_dims)\n",
    "        self.kernel = self.add_weight(name='capsule_kernel',\n",
    "                                      shape=(self.num_capsules, input_shape[-2],\n",
    "                                             self.dim_capsules, input_shape[-1]),\n",
    "                                      initializer='glorot_uniform',\n",
    "                                      trainable=True)\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "        # Compute dot product between inputs and weights\n",
    "        u_hat = tf.keras.backend.batch_dot(inputs, self.kernel, [-1, -1])\n",
    "        return u_hat  # Quick example without routing\n",
    "\n"
   ],
   "id": "8c9887043d035b5e",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-17T04:24:37.358681Z",
     "start_time": "2025-12-17T04:24:36.540740Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "def create_capsnet(input_shape):\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    x = layers.Conv2D(256, 9, activation='relu')(inputs)\n",
    "    x = layers.Conv2D(256, 9, activation='relu')(x)\n",
    "    capsule = CapsuleLayer(num_capsules=10, dim_capsules=16)(x)  # Example params\n",
    "    outputs = capsule\n",
    "    model = models.Model(inputs=inputs, outputs=outputs, name='capsnet_model')\n",
    "    return model\n",
    "\n",
    "capsnet = create_capsnet((28, 28, 1))\n",
    "capsnet.summary()\n"
   ],
   "id": "17b6a57dde265e68",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\User\\PycharmProjects\\pythonProject3\\.venv\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\core.py:232: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1mModel: \"capsnet_model\"\u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"capsnet_model\"</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001B[1m \u001B[0m\u001B[1mLayer (type)                   \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape          \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m      Param #\u001B[0m\u001B[1m \u001B[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001B[38;5;33mInputLayer\u001B[0m)        │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m28\u001B[0m, \u001B[38;5;34m28\u001B[0m, \u001B[38;5;34m1\u001B[0m)      │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d (\u001B[38;5;33mConv2D\u001B[0m)                 │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m20\u001B[0m, \u001B[38;5;34m20\u001B[0m, \u001B[38;5;34m256\u001B[0m)    │        \u001B[38;5;34m20,992\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (\u001B[38;5;33mConv2D\u001B[0m)               │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m12\u001B[0m, \u001B[38;5;34m12\u001B[0m, \u001B[38;5;34m256\u001B[0m)    │     \u001B[38;5;34m5,308,672\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ capsule_layer (\u001B[38;5;33mCapsuleLayer\u001B[0m)    │ (\u001B[38;5;34m10\u001B[0m, \u001B[38;5;34m12\u001B[0m, \u001B[38;5;34m12\u001B[0m, \u001B[38;5;34m12\u001B[0m, \u001B[38;5;34m16\u001B[0m)   │       \u001B[38;5;34m491,520\u001B[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">20,992</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">5,308,672</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ capsule_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">CapsuleLayer</span>)    │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │       <span style=\"color: #00af00; text-decoration-color: #00af00\">491,520</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Total params: \u001B[0m\u001B[38;5;34m5,821,184\u001B[0m (22.21 MB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,821,184</span> (22.21 MB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Trainable params: \u001B[0m\u001B[38;5;34m5,821,184\u001B[0m (22.21 MB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,821,184</span> (22.21 MB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Non-trainable params: \u001B[0m\u001B[38;5;34m0\u001B[0m (0.00 B)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-17T04:24:57.260063Z",
     "start_time": "2025-12-17T04:24:57.040434Z"
    }
   },
   "cell_type": "code",
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = datasets.mnist.load_data()\n",
    "\n",
    "# Normalize images to the range of [0,1]\n",
    "train_images = train_images.astype('float32') / 255.\n",
    "test_images = test_images.astype('float32') / 255.\n",
    "\n",
    "# Reshape images to include channels\n",
    "train_images = np.expand_dims(train_images, -1)\n",
    "test_images = np.expand_dims(test_images, -1)\n",
    "\n",
    "# Convert labels to one-hot encoding\n",
    "train_labels = utils.to_categorical(train_labels, 10)\n",
    "test_labels = utils.to_categorical(test_labels, 10)"
   ],
   "id": "f388437a215513d3",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-17T04:25:05.770280Z",
     "start_time": "2025-12-17T04:25:05.600121Z"
    }
   },
   "cell_type": "code",
   "source": [
    "capsnet.compile(optimizer='adam', loss='mse', metrics=['accuracy'])\n",
    "\n",
    "# Train the network\n",
    "history = capsnet.fit(train_images, train_labels,\n",
    "                      batch_size=128,\n",
    "                      epochs=10,\n",
    "                      validation_split=0.2)"
   ],
   "id": "eda73c5b5b2ce725",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling CapsuleLayer.call().\n\n\u001B[1mCannot do batch_dot on inputs with different batch sizes. Received inputs with tf.shapes (128, 12, 12, 256) and (10, 12, 16, 256).\u001B[0m\n\nArguments received by CapsuleLayer.call():\n  • inputs=tf.Tensor(shape=(128, 12, 12, 256), dtype=float32)\n  • training=True",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mValueError\u001B[39m                                Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[6]\u001B[39m\u001B[32m, line 4\u001B[39m\n\u001B[32m      1\u001B[39m capsnet.compile(optimizer=\u001B[33m'\u001B[39m\u001B[33madam\u001B[39m\u001B[33m'\u001B[39m, loss=\u001B[33m'\u001B[39m\u001B[33mmse\u001B[39m\u001B[33m'\u001B[39m, metrics=[\u001B[33m'\u001B[39m\u001B[33maccuracy\u001B[39m\u001B[33m'\u001B[39m])\n\u001B[32m      3\u001B[39m \u001B[38;5;66;03m# Train the network\u001B[39;00m\n\u001B[32m----> \u001B[39m\u001B[32m4\u001B[39m history = \u001B[43mcapsnet\u001B[49m\u001B[43m.\u001B[49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_images\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_labels\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m      5\u001B[39m \u001B[43m                      \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m128\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m      6\u001B[39m \u001B[43m                      \u001B[49m\u001B[43mepochs\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m10\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m      7\u001B[39m \u001B[43m                      \u001B[49m\u001B[43mvalidation_split\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m0.2\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\pythonProject3\\.venv\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001B[39m, in \u001B[36mfilter_traceback.<locals>.error_handler\u001B[39m\u001B[34m(*args, **kwargs)\u001B[39m\n\u001B[32m    119\u001B[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n\u001B[32m    120\u001B[39m     \u001B[38;5;66;03m# To get the full stack trace, call:\u001B[39;00m\n\u001B[32m    121\u001B[39m     \u001B[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m122\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m e.with_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m    123\u001B[39m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[32m    124\u001B[39m     \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[3]\u001B[39m\u001B[32m, line 18\u001B[39m, in \u001B[36mCapsuleLayer.call\u001B[39m\u001B[34m(self, inputs, training)\u001B[39m\n\u001B[32m     16\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mcall\u001B[39m(\u001B[38;5;28mself\u001B[39m, inputs, training=\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[32m     17\u001B[39m     \u001B[38;5;66;03m# Compute dot product between inputs and weights\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m18\u001B[39m     u_hat = \u001B[43mtf\u001B[49m\u001B[43m.\u001B[49m\u001B[43mkeras\u001B[49m\u001B[43m.\u001B[49m\u001B[43mbackend\u001B[49m\u001B[43m.\u001B[49m\u001B[43mbatch_dot\u001B[49m\u001B[43m(\u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mkernel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m[\u001B[49m\u001B[43m-\u001B[49m\u001B[32;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m-\u001B[49m\u001B[32;43m1\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     19\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m u_hat\n",
      "\u001B[31mValueError\u001B[39m: Exception encountered when calling CapsuleLayer.call().\n\n\u001B[1mCannot do batch_dot on inputs with different batch sizes. Received inputs with tf.shapes (128, 12, 12, 256) and (10, 12, 16, 256).\u001B[0m\n\nArguments received by CapsuleLayer.call():\n  • inputs=tf.Tensor(shape=(128, 12, 12, 256), dtype=float32)\n  • training=True"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-17T04:25:17.938200Z",
     "start_time": "2025-12-17T04:25:17.846045Z"
    }
   },
   "cell_type": "code",
   "source": [
    "test_loss, test_accuracy = capsnet.evaluate(test_images, test_labels)\n",
    "print(f\"Test accuracy: {test_accuracy}\")"
   ],
   "id": "3a4c47e03f2b76d9",
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Dimensions must be equal, but are 10 and 16 for '{{node compile_loss/mse/sub}} = Sub[T=DT_FLOAT](data_1, capsnet_model_1/capsule_layer_1/Reshape_2)' with input shapes: [?,10], [10,12,12,12,16].",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mValueError\u001B[39m                                Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[7]\u001B[39m\u001B[32m, line 1\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m1\u001B[39m test_loss, test_accuracy = \u001B[43mcapsnet\u001B[49m\u001B[43m.\u001B[49m\u001B[43mevaluate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtest_images\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtest_labels\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m      2\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mTest accuracy: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtest_accuracy\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\pythonProject3\\.venv\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001B[39m, in \u001B[36mfilter_traceback.<locals>.error_handler\u001B[39m\u001B[34m(*args, **kwargs)\u001B[39m\n\u001B[32m    119\u001B[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n\u001B[32m    120\u001B[39m     \u001B[38;5;66;03m# To get the full stack trace, call:\u001B[39;00m\n\u001B[32m    121\u001B[39m     \u001B[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m122\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m e.with_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m    123\u001B[39m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[32m    124\u001B[39m     \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\pythonProject3\\.venv\\Lib\\site-packages\\keras\\src\\losses\\losses.py:1763\u001B[39m, in \u001B[36mmean_squared_error\u001B[39m\u001B[34m(y_true, y_pred)\u001B[39m\n\u001B[32m   1761\u001B[39m y_true = ops.convert_to_tensor(y_true, dtype=y_pred.dtype)\n\u001B[32m   1762\u001B[39m y_true, y_pred = squeeze_or_expand_to_same_rank(y_true, y_pred)\n\u001B[32m-> \u001B[39m\u001B[32m1763\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m ops.mean(ops.square(\u001B[43my_true\u001B[49m\u001B[43m \u001B[49m\u001B[43m-\u001B[49m\u001B[43m \u001B[49m\u001B[43my_pred\u001B[49m), axis=-\u001B[32m1\u001B[39m)\n",
      "\u001B[31mValueError\u001B[39m: Dimensions must be equal, but are 10 and 16 for '{{node compile_loss/mse/sub}} = Sub[T=DT_FLOAT](data_1, capsnet_model_1/capsule_layer_1/Reshape_2)' with input shapes: [?,10], [10,12,12,12,16]."
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-17T04:25:25.502996Z",
     "start_time": "2025-12-17T04:25:25.445220Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_examples(images, labels, predictions):\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=5, figsize=(15, 3))\n",
    "    for i in range(5):\n",
    "        axes[i].imshow(images[i].squeeze(), cmap='gray')\n",
    "        true_label = np.argmax(labels[i])\n",
    "        predicted_label = np.argmax(predictions[i])\n",
    "        axes[i].set_title(f'True: {true_label}, Pred: {predicted_label}')\n",
    "        axes[i].axis('off')\n",
    "\n",
    "predictions = capsnet.predict(test_images[:5])\n",
    "plot_examples(test_images[:5], test_labels[:5], predictions)"
   ],
   "id": "8d4119fc3c584bfb",
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling CapsuleLayer.call().\n\n\u001B[1mCannot do batch_dot on inputs with different batch sizes. Received inputs with tf.shapes (5, 12, 12, 256) and (10, 12, 16, 256).\u001B[0m\n\nArguments received by CapsuleLayer.call():\n  • inputs=tf.Tensor(shape=(5, 12, 12, 256), dtype=float32)\n  • training=False",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mValueError\u001B[39m                                Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[8]\u001B[39m\u001B[32m, line 12\u001B[39m\n\u001B[32m      9\u001B[39m         axes[i].set_title(\u001B[33mf\u001B[39m\u001B[33m'\u001B[39m\u001B[33mTrue: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtrue_label\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m, Pred: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mpredicted_label\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m'\u001B[39m)\n\u001B[32m     10\u001B[39m         axes[i].axis(\u001B[33m'\u001B[39m\u001B[33moff\u001B[39m\u001B[33m'\u001B[39m)\n\u001B[32m---> \u001B[39m\u001B[32m12\u001B[39m predictions = \u001B[43mcapsnet\u001B[49m\u001B[43m.\u001B[49m\u001B[43mpredict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtest_images\u001B[49m\u001B[43m[\u001B[49m\u001B[43m:\u001B[49m\u001B[32;43m5\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     13\u001B[39m plot_examples(test_images[:\u001B[32m5\u001B[39m], test_labels[:\u001B[32m5\u001B[39m], predictions)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\pythonProject3\\.venv\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001B[39m, in \u001B[36mfilter_traceback.<locals>.error_handler\u001B[39m\u001B[34m(*args, **kwargs)\u001B[39m\n\u001B[32m    119\u001B[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n\u001B[32m    120\u001B[39m     \u001B[38;5;66;03m# To get the full stack trace, call:\u001B[39;00m\n\u001B[32m    121\u001B[39m     \u001B[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m122\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m e.with_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m    123\u001B[39m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[32m    124\u001B[39m     \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[3]\u001B[39m\u001B[32m, line 18\u001B[39m, in \u001B[36mCapsuleLayer.call\u001B[39m\u001B[34m(self, inputs, training)\u001B[39m\n\u001B[32m     16\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mcall\u001B[39m(\u001B[38;5;28mself\u001B[39m, inputs, training=\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[32m     17\u001B[39m     \u001B[38;5;66;03m# Compute dot product between inputs and weights\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m18\u001B[39m     u_hat = \u001B[43mtf\u001B[49m\u001B[43m.\u001B[49m\u001B[43mkeras\u001B[49m\u001B[43m.\u001B[49m\u001B[43mbackend\u001B[49m\u001B[43m.\u001B[49m\u001B[43mbatch_dot\u001B[49m\u001B[43m(\u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mkernel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m[\u001B[49m\u001B[43m-\u001B[49m\u001B[32;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m-\u001B[49m\u001B[32;43m1\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     19\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m u_hat\n",
      "\u001B[31mValueError\u001B[39m: Exception encountered when calling CapsuleLayer.call().\n\n\u001B[1mCannot do batch_dot on inputs with different batch sizes. Received inputs with tf.shapes (5, 12, 12, 256) and (10, 12, 16, 256).\u001B[0m\n\nArguments received by CapsuleLayer.call():\n  • inputs=tf.Tensor(shape=(5, 12, 12, 256), dtype=float32)\n  • training=False"
     ]
    }
   ],
   "execution_count": 8
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
